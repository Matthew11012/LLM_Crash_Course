{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76221156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import CharTokenizer, CharDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722d781e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 [0, 14, 15, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "text = \"To be or not to be\"\n",
    "tok = CharTokenizer(text)\n",
    "print(tok.vocab_size, tok.encode(\"To be\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "305671d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: ['T', 'o', ' ', 'b', 'e', ' ', 'o', 'r']\n",
      "y: ['o', ' ', 'b', 'e', ' ', 'o', 'r', ' ']\n"
     ]
    }
   ],
   "source": [
    "dataset = CharDataset(text, tok, seq_len=8)\n",
    "x, y = dataset[0]\n",
    "print(\"x:\", tok.decode(x.tolist()))\n",
    "print(\"y:\", tok.decode(y.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e70dde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 14, 15, 16, 17, 15, 14,  7])\n",
      "tensor([14, 15, 16, 17, 15, 14,  7, 15])\n",
      "(tensor([ 0, 14, 15, 16, 17, 15, 14,  7]), tensor([14, 15, 16, 17, 15, 14,  7, 15]))\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa554130",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2fd7cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 53\n",
      "x0 text: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
      "y0 text: ['b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']\n",
      "torch.Size([4, 8]) torch.Size([4, 8])\n",
      "vocab_size: 53\n",
      "max token id in batch: 44\n",
      "min token id in batch: 9\n",
      "Tokenizer vocab size: 53\n",
      "First 20 vocab items: [('a', 0), ('b', 1), ('c', 2), ('d', 3), ('e', 4), ('f', 5), ('g', 6), ('h', 7), ('i', 8), ('j', 9), ('k', 10), ('l', 11), ('m', 12), ('n', 13), ('o', 14), ('p', 15), ('q', 16), ('r', 17), ('s', 18), ('t', 19)]\n",
      "Sample tokens: [7, 4, 11, 11, 14]\n",
      "loss: 81.9527359008789\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from model import TinyGPT\n",
    "\n",
    "# 1) Tokenizer\n",
    "tok = CharTokenizer(text)\n",
    "print(\"Vocab size:\", tok.vocab_size)\n",
    "# print(tok.decode(tok.encode(\"To be\")))\n",
    "assert \"\".join(tok.decode(tok.encode(\"To be\"))) == \"To be\"\n",
    "\n",
    "# 2) Dataset\n",
    "dataset = CharDataset(text, tok, seq_len=8)\n",
    "x0, y0 = dataset[0]\n",
    "print(\"x0 text:\", tok.decode(x0.tolist()))\n",
    "print(\"y0 text:\", tok.decode(y0.tolist()))\n",
    "# Check shift property:\n",
    "\n",
    "assert tok.decode(y0.tolist()) == tok.decode(x0.tolist())[1:] + [text[len(x0)+0:len(x0)+1]]\n",
    "\n",
    "# 3) DataLoader shapes\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "xb, yb = next(iter(loader))\n",
    "print(xb.shape, yb.shape)  # torch.Size([4, 8])\n",
    "\n",
    "# 4) Quick forward\n",
    "vocab_size = tok.vocab_size\n",
    "max_seq_len = 8\n",
    "print(\"vocab_size:\", vocab_size)\n",
    "print(\"max token id in batch:\", int(xb.max()))\n",
    "print(\"min token id in batch:\", int(xb.min()))\n",
    "print(\"Tokenizer vocab size:\", tok.vocab_size)\n",
    "print(\"First 20 vocab items:\", list(tok.stoi.items())[:20])\n",
    "print(\"Sample tokens:\", tok.encode(\"hello\"))\n",
    "\n",
    "model = TinyGPT(vocab_size=vocab_size,\n",
    "    d_model=128,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    max_seq_len=max_seq_len)  # (4, 8, vocab_size)\n",
    "logits = model(xb)   # xb is [batch, seq]\n",
    "loss = F.cross_entropy(logits.view(-1, tok.vocab_size), yb.view(-1))    \n",
    "print(\"loss:\", float(loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e1e0c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | loss 80.4481\n",
      "epoch 2 | loss 75.6305\n",
      "epoch 3 | loss 69.3849\n",
      "epoch 4 | loss 62.4998\n",
      "epoch 5 | loss 54.9131\n",
      "epoch 6 | loss 47.3770\n",
      "epoch 7 | loss 39.7089\n",
      "epoch 8 | loss 34.0720\n",
      "epoch 9 | loss 28.6085\n",
      "epoch 10 | loss 24.3922\n",
      "epoch 11 | loss 21.6750\n",
      "epoch 12 | loss 19.0757\n",
      "epoch 13 | loss 16.8837\n",
      "epoch 14 | loss 15.4192\n",
      "epoch 15 | loss 13.3221\n",
      "epoch 16 | loss 11.8220\n",
      "epoch 17 | loss 10.3131\n",
      "epoch 18 | loss 9.0567\n",
      "epoch 19 | loss 8.6834\n",
      "epoch 20 | loss 7.5065\n",
      "epoch 21 | loss 6.6527\n",
      "epoch 22 | loss 6.1665\n",
      "epoch 23 | loss 5.1758\n",
      "epoch 24 | loss 4.5770\n",
      "epoch 25 | loss 4.5040\n",
      "epoch 26 | loss 4.1472\n",
      "epoch 27 | loss 4.3506\n",
      "epoch 28 | loss 3.4856\n",
      "epoch 29 | loss 3.1945\n",
      "epoch 30 | loss 3.0242\n",
      "epoch 31 | loss 2.7820\n",
      "epoch 32 | loss 2.6192\n",
      "epoch 33 | loss 2.4870\n",
      "epoch 34 | loss 2.1806\n",
      "epoch 35 | loss 2.0950\n",
      "epoch 36 | loss 1.8373\n",
      "epoch 37 | loss 1.9985\n",
      "epoch 38 | loss 1.6386\n",
      "epoch 39 | loss 1.4877\n",
      "epoch 40 | loss 1.3815\n",
      "epoch 41 | loss 1.5043\n",
      "epoch 42 | loss 1.4332\n",
      "epoch 43 | loss 1.3589\n",
      "epoch 44 | loss 1.1639\n",
      "epoch 45 | loss 1.2158\n",
      "epoch 46 | loss 0.9902\n",
      "epoch 47 | loss 0.8782\n",
      "epoch 48 | loss 0.8963\n",
      "epoch 49 | loss 0.8835\n",
      "epoch 50 | loss 1.0057\n",
      "epoch 51 | loss 0.8321\n",
      "epoch 52 | loss 0.8918\n",
      "epoch 53 | loss 0.7972\n",
      "epoch 54 | loss 0.6329\n",
      "epoch 55 | loss 0.8169\n",
      "epoch 56 | loss 0.4949\n",
      "epoch 57 | loss 0.6915\n",
      "epoch 58 | loss 0.4116\n",
      "epoch 59 | loss 0.5464\n",
      "epoch 60 | loss 0.6331\n",
      "epoch 61 | loss 0.5773\n",
      "epoch 62 | loss 0.3534\n",
      "epoch 63 | loss 0.5127\n",
      "epoch 64 | loss 0.5606\n",
      "epoch 65 | loss 0.4707\n",
      "epoch 66 | loss 0.5920\n",
      "epoch 67 | loss 0.4020\n",
      "epoch 68 | loss 0.4009\n",
      "epoch 69 | loss 0.4482\n",
      "epoch 70 | loss 0.3555\n",
      "epoch 71 | loss 0.2902\n",
      "epoch 72 | loss 0.2868\n",
      "epoch 73 | loss 0.4345\n",
      "epoch 74 | loss 0.4101\n",
      "epoch 75 | loss 0.3851\n",
      "epoch 76 | loss 0.2483\n",
      "epoch 77 | loss 0.2450\n",
      "epoch 78 | loss 0.2518\n",
      "epoch 79 | loss 0.2201\n",
      "epoch 80 | loss 0.2861\n",
      "epoch 81 | loss 0.2572\n",
      "epoch 82 | loss 0.2240\n",
      "epoch 83 | loss 0.1968\n",
      "epoch 84 | loss 0.1500\n",
      "epoch 85 | loss 0.1446\n",
      "epoch 86 | loss 0.2332\n",
      "epoch 87 | loss 0.1372\n",
      "epoch 88 | loss 0.1725\n",
      "epoch 89 | loss 0.0689\n",
      "epoch 90 | loss 0.0862\n",
      "epoch 91 | loss 0.0988\n",
      "epoch 92 | loss 0.0826\n",
      "epoch 93 | loss 0.0683\n",
      "epoch 94 | loss 0.1329\n",
      "epoch 95 | loss 0.0728\n",
      "epoch 96 | loss 0.0977\n",
      "epoch 97 | loss 0.0813\n",
      "epoch 98 | loss 0.0523\n",
      "epoch 99 | loss 0.0732\n",
      "epoch 100 | loss 0.0712\n",
      "epoch 101 | loss 0.0800\n",
      "epoch 102 | loss 0.1254\n",
      "epoch 103 | loss 0.0310\n",
      "epoch 104 | loss 0.0625\n",
      "epoch 105 | loss 0.0307\n",
      "epoch 106 | loss 0.0382\n",
      "epoch 107 | loss 0.0440\n",
      "epoch 108 | loss 0.0354\n",
      "epoch 109 | loss 0.0433\n",
      "epoch 110 | loss 0.0709\n",
      "epoch 111 | loss 0.0579\n",
      "epoch 112 | loss 0.0507\n",
      "epoch 113 | loss 0.0314\n",
      "epoch 114 | loss 0.0346\n",
      "epoch 115 | loss 0.0174\n",
      "epoch 116 | loss 0.0224\n",
      "epoch 117 | loss 0.0242\n",
      "epoch 118 | loss 0.0297\n",
      "epoch 119 | loss 0.0246\n",
      "epoch 120 | loss 0.0216\n",
      "epoch 121 | loss 0.0239\n",
      "epoch 122 | loss 0.0107\n",
      "epoch 123 | loss 0.0172\n",
      "epoch 124 | loss 0.0126\n",
      "epoch 125 | loss 0.0146\n",
      "epoch 126 | loss 0.0133\n",
      "epoch 127 | loss 0.0163\n",
      "epoch 128 | loss 0.0140\n",
      "epoch 129 | loss 0.0121\n",
      "epoch 130 | loss 0.0196\n",
      "epoch 131 | loss 0.0130\n",
      "epoch 132 | loss 0.0172\n",
      "epoch 133 | loss 0.0119\n",
      "epoch 134 | loss 0.0170\n",
      "epoch 135 | loss 0.0183\n",
      "epoch 136 | loss 0.0131\n",
      "epoch 137 | loss 0.0102\n",
      "epoch 138 | loss 0.0118\n",
      "epoch 139 | loss 0.0083\n",
      "epoch 140 | loss 0.0112\n",
      "epoch 141 | loss 0.0092\n",
      "epoch 142 | loss 0.0087\n",
      "epoch 143 | loss 0.0057\n",
      "epoch 144 | loss 0.0061\n",
      "epoch 145 | loss 0.0058\n",
      "epoch 146 | loss 0.0069\n",
      "epoch 147 | loss 0.0092\n",
      "epoch 148 | loss 0.0070\n",
      "epoch 149 | loss 0.0056\n",
      "epoch 150 | loss 0.0064\n",
      "epoch 151 | loss 0.0068\n",
      "epoch 152 | loss 0.0064\n",
      "epoch 153 | loss 0.0057\n",
      "epoch 154 | loss 0.0061\n",
      "epoch 155 | loss 0.0060\n",
      "epoch 156 | loss 0.0070\n",
      "epoch 157 | loss 0.0045\n",
      "epoch 158 | loss 0.0047\n",
      "epoch 159 | loss 0.0036\n",
      "epoch 160 | loss 0.0044\n",
      "epoch 161 | loss 0.0045\n",
      "epoch 162 | loss 0.0041\n",
      "epoch 163 | loss 0.0038\n",
      "epoch 164 | loss 0.0034\n",
      "epoch 165 | loss 0.0041\n",
      "epoch 166 | loss 0.0051\n",
      "epoch 167 | loss 0.0036\n",
      "epoch 168 | loss 0.0042\n",
      "epoch 169 | loss 0.0035\n",
      "epoch 170 | loss 0.0033\n",
      "epoch 171 | loss 0.0036\n",
      "epoch 172 | loss 0.0029\n",
      "epoch 173 | loss 0.0033\n",
      "epoch 174 | loss 0.0040\n",
      "epoch 175 | loss 0.0027\n",
      "epoch 176 | loss 0.0036\n",
      "epoch 177 | loss 0.0035\n",
      "epoch 178 | loss 0.0027\n",
      "epoch 179 | loss 0.0028\n",
      "epoch 180 | loss 0.0031\n",
      "epoch 181 | loss 0.0035\n",
      "epoch 182 | loss 0.0023\n",
      "epoch 183 | loss 0.0023\n",
      "epoch 184 | loss 0.0032\n",
      "epoch 185 | loss 0.0020\n",
      "epoch 186 | loss 0.0030\n",
      "epoch 187 | loss 0.0021\n",
      "epoch 188 | loss 0.0025\n",
      "epoch 189 | loss 0.0022\n",
      "epoch 190 | loss 0.0029\n",
      "epoch 191 | loss 0.0024\n",
      "epoch 192 | loss 0.0022\n",
      "epoch 193 | loss 0.0025\n",
      "epoch 194 | loss 0.0022\n",
      "epoch 195 | loss 0.0021\n",
      "epoch 196 | loss 0.0018\n",
      "epoch 197 | loss 0.0026\n",
      "epoch 198 | loss 0.0024\n",
      "epoch 199 | loss 0.0027\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# hyperparams\n",
    "batch_size = 16\n",
    "seq_len = 32\n",
    "epochs = 200\n",
    "\n",
    "# make training data (you can sample random sequences from your text)\n",
    "def get_batch(text, block_size=seq_len, batch_size=batch_size):\n",
    "    ix = torch.randint(len(text) - block_size, (batch_size,))\n",
    "    x = torch.stack([torch.tensor(tok.encode(text[i:i+block_size])) for i in ix])\n",
    "    y = torch.stack([torch.tensor(tok.encode(text[i+1:i+block_size+1])) for i in ix])\n",
    "    return x, y\n",
    "\n",
    "# model, optimizer\n",
    "model = TinyGPT(vocab_size=tok.vocab_size, d_model=128, n_heads=4, n_layers=2, max_seq_len=seq_len)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(epochs):\n",
    "    xb, yb = get_batch(text)\n",
    "    logits = model(xb)\n",
    "    loss = F.cross_entropy(logits.view(-1, tok.vocab_size), yb.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch :\n",
    "        print(f\"epoch {epoch} | loss {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea083316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_emb.weight torch.Size([53, 128])\n",
      "pos_emb.weight torch.Size([32, 128])\n",
      "blocks.0.ln1.weight torch.Size([128])\n",
      "blocks.0.ln1.bias torch.Size([128])\n",
      "blocks.0.mha.W_q.weight torch.Size([128, 128])\n",
      "blocks.0.mha.W_q.bias torch.Size([128])\n",
      "blocks.0.mha.W_k.weight torch.Size([128, 128])\n",
      "blocks.0.mha.W_k.bias torch.Size([128])\n",
      "blocks.0.mha.W_v.weight torch.Size([128, 128])\n",
      "blocks.0.mha.W_v.bias torch.Size([128])\n",
      "blocks.0.mha.W_o.weight torch.Size([128, 128])\n",
      "blocks.0.mha.W_o.bias torch.Size([128])\n",
      "blocks.0.ln2.weight torch.Size([128])\n",
      "blocks.0.ln2.bias torch.Size([128])\n",
      "blocks.0.mlp.fc1.weight torch.Size([512, 128])\n",
      "blocks.0.mlp.fc1.bias torch.Size([512])\n",
      "blocks.0.mlp.fc2.weight torch.Size([128, 512])\n",
      "blocks.0.mlp.fc2.bias torch.Size([128])\n",
      "blocks.1.ln1.weight torch.Size([128])\n",
      "blocks.1.ln1.bias torch.Size([128])\n",
      "blocks.1.mha.W_q.weight torch.Size([128, 128])\n",
      "blocks.1.mha.W_q.bias torch.Size([128])\n",
      "blocks.1.mha.W_k.weight torch.Size([128, 128])\n",
      "blocks.1.mha.W_k.bias torch.Size([128])\n",
      "blocks.1.mha.W_v.weight torch.Size([128, 128])\n",
      "blocks.1.mha.W_v.bias torch.Size([128])\n",
      "blocks.1.mha.W_o.weight torch.Size([128, 128])\n",
      "blocks.1.mha.W_o.bias torch.Size([128])\n",
      "blocks.1.ln2.weight torch.Size([128])\n",
      "blocks.1.ln2.bias torch.Size([128])\n",
      "blocks.1.mlp.fc1.weight torch.Size([512, 128])\n",
      "blocks.1.mlp.fc1.bias torch.Size([512])\n",
      "blocks.1.mlp.fc2.weight torch.Size([128, 512])\n",
      "blocks.1.mlp.fc2.bias torch.Size([128])\n",
      "ln_f.weight torch.Size([128])\n",
      "ln_f.bias torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
